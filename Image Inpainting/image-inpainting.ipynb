{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"TD4 : Image impainting","metadata":{"id":"PXgwHKb3ie0w"}},{"cell_type":"markdown","source":"INSA HdF\nS. Delprat","metadata":{"id":"Vr7SNkMSU52F"}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport io\nimport os\n\nfrom IPython.display import clear_output","metadata":{"id":"S_Y46FckiSyI","execution":{"iopub.status.busy":"2022-04-18T08:38:44.109219Z","iopub.execute_input":"2022-04-18T08:38:44.109686Z","iopub.status.idle":"2022-04-18T08:38:49.090599Z","shell.execute_reply.started":"2022-04-18T08:38:44.109609Z","shell.execute_reply":"2022-04-18T08:38:49.088655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if 1==1:\n#     # if you use google drive, then update the folder according to its structure\n#     baseFolder='/content/gdrive/MyDrive/Colab Notebooks/TD/TD4 Impainting'\n#     from google.colab import drive\n#     drive.mount(\"/content/gdrive\")\n# else:\n#     # kaggle default folder for this dataset\nbaseFolder = '../input/inpaintingdataset/'","metadata":{"id":"X_s-hn9GUPZs","outputId":"1236ca54-018c-4f04-9b86-d87824d593d9","execution":{"iopub.status.busy":"2022-04-18T08:38:49.095479Z","iopub.execute_input":"2022-04-18T08:38:49.097464Z","iopub.status.idle":"2022-04-18T08:38:49.106361Z","shell.execute_reply.started":"2022-04-18T08:38:49.097423Z","shell.execute_reply":"2022-04-18T08:38:49.103977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_height = 512\nimg_width = 512","metadata":{"id":"sGfcjw48j5Mu","execution":{"iopub.status.busy":"2022-04-18T08:38:49.112111Z","iopub.execute_input":"2022-04-18T08:38:49.114588Z","iopub.status.idle":"2022-04-18T08:38:49.122632Z","shell.execute_reply.started":"2022-04-18T08:38:49.114541Z","shell.execute_reply":"2022-04-18T08:38:49.121894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tensor_info(Img,name='img'):\n    print(name,' min : ',tf.math.reduce_min(Img).numpy(),' Max : ',tf.math.reduce_max(Img).numpy(),' type : ',Img.dtype, ' shape : ',Img.shape.as_list())    ","metadata":{"id":"kIpjJYlyIfZT","execution":{"iopub.status.busy":"2022-04-18T08:38:49.127281Z","iopub.execute_input":"2022-04-18T08:38:49.128799Z","iopub.status.idle":"2022-04-18T08:38:49.13677Z","shell.execute_reply.started":"2022-04-18T08:38:49.128755Z","shell.execute_reply":"2022-04-18T08:38:49.136022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Read an image.\n1.   Resize the image if resize_needed==True\n2.   Rescale the pixels value into -1,1 if rescale_symetric==True\n\nrescale_symetric should be False for the mask such that the output is 0-1 and not (-1,1)\n","metadata":{"id":"esE1wBfxVPAM"}},{"cell_type":"code","source":"def read_image(filename,resize_needed,rescale_symetric=True):\n    image = tf.io.read_file(filename)\n    image = tf.image.decode_png(image, channels=3)\n    if resize_needed:\n        image = tf.image.resize(image, [img_height, img_width])\n    else:\n        image = tf.cast(image,tf.float32)\n    if rescale_symetric:\n        image = (image-127.5)/127.5\n    else:\n        image=image/255.0\n    image = tf.expand_dims(image,axis=0)\n    return image","metadata":{"id":"9LbjYH-BjzHr","execution":{"iopub.status.busy":"2022-04-18T08:38:49.142418Z","iopub.execute_input":"2022-04-18T08:38:49.144632Z","iopub.status.idle":"2022-04-18T08:38:49.153876Z","shell.execute_reply.started":"2022-04-18T08:38:49.144594Z","shell.execute_reply":"2022-04-18T08:38:49.153084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Q1) Ecrire la fonction buildDecoder\n\nEn entrée: \n+ inputShape : size (nx x nx x nz) of the input image (fixed noise prior)\n+ nc : list whose every element is the number of conv filter in each block\n+ display : boolean indicating wether of not the model summary should be displayed\n\noutput:\n+ model\n","metadata":{"id":"4vg23WfVcOHN"}},{"cell_type":"code","source":"def buildDecoder(inputShape,nc,display=False):\n    # Input\n    Input = layers.Input(shape=inputShape)\n    \n    # Block 1\n    x = layers.Conv2D(filters=nc[0], kernel_size=1, kernel_initializer=tf.keras.initializers.HeNormal(), strides=1, padding=\"same\", use_bias=\"False\")(Input)\n    x = layers.BatchNormalization(momentum=0.9, epsilon=1e-5)(x)\n    x = layers.ReLU()(x)\n    \n    # Block 2\n    x = layers.UpSampling2D(interpolation=\"bilinear\")(x)\n    x = layers.Conv2D(filters=nc[1], kernel_size=1, kernel_initializer=tf.keras.initializers.HeNormal(), strides=1, padding=\"same\", use_bias=\"False\")(x)\n    x = layers.BatchNormalization(momentum=0.9, epsilon=1e-5)(x)\n    x = layers.ReLU()(x)\n    \n    # Block 3\n    x = layers.UpSampling2D(interpolation=\"bilinear\")(x)\n    x = layers.Conv2D(filters=nc[2], kernel_size=1, kernel_initializer=tf.keras.initializers.HeNormal(), strides=1, padding=\"same\", use_bias=\"False\")(x)\n    x = layers.BatchNormalization(momentum=0.9, epsilon=1e-5)(x)\n    x = layers.ReLU()(x)\n    \n    # Block 4\n    x = layers.UpSampling2D(interpolation=\"bilinear\")(x)\n    x = layers.Conv2D(filters=nc[3], kernel_size=1, kernel_initializer=tf.keras.initializers.HeNormal(), strides=1, padding=\"same\", use_bias=\"False\")(x)\n    x = layers.BatchNormalization(momentum=0.9, epsilon=1e-5)(x)\n    x = layers.ReLU()(x)\n    \n    # Block 5\n    x = layers.UpSampling2D(interpolation=\"bilinear\")(x)\n    x = layers.Conv2D(filters=nc[4], kernel_size=1, kernel_initializer=tf.keras.initializers.HeNormal(), strides=1, padding=\"same\", use_bias=\"False\")(x)\n    x = layers.BatchNormalization(momentum=0.9, epsilon=1e-5)(x)\n    x = layers.ReLU()(x)\n    \n    # Block 6\n    x = layers.UpSampling2D(interpolation=\"bilinear\")(x)\n    x = layers.Conv2D(filters=nc[5], kernel_size=1, kernel_initializer=tf.keras.initializers.HeNormal(), strides=1, padding=\"same\", use_bias=\"False\")(x)\n    x = layers.BatchNormalization(momentum=0.9, epsilon=1e-5)(x)\n    x = layers.ReLU()(x)\n    \n    # Final block\n    x = layers.Conv2D(filters=3, kernel_size=1, kernel_initializer=tf.keras.initializers.HeNormal(), strides=1, padding=\"same\", use_bias=\"False\", activation=\"tanh\")(x)\n    \n    # Model\n    model = tf.keras.Model(Input, x)\n    \n    if display:\n        print(model.summary())\n    \n    return model","metadata":{"id":"1P_jDR-8UMZN","execution":{"iopub.status.busy":"2022-04-18T08:38:49.159188Z","iopub.execute_input":"2022-04-18T08:38:49.161776Z","iopub.status.idle":"2022-04-18T08:38:49.18865Z","shell.execute_reply.started":"2022-04-18T08:38:49.161735Z","shell.execute_reply":"2022-04-18T08:38:49.187494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display(imgTarget,img,allLoss):\n    clear_output(wait=True)\n    plt.figure(figsize=[20,10])\n    plt.subplot(1,3,1)\n    plt.imshow(img[0,:,:,:]*0.5+0.5)\n    plt.axis('off')\n    plt.subplot(1,3,2)\n    plt.imshow(imgTarget[0,:,:,:]*0.5+0.5)\n    plt.axis('off')\n    plt.subplot(1,3,3)\n    plt.plot(allLoss)\n    plt.show()","metadata":{"id":"wCZO4bqFBLhA","execution":{"iopub.status.busy":"2022-04-18T08:38:49.192976Z","iopub.execute_input":"2022-04-18T08:38:49.195434Z","iopub.status.idle":"2022-04-18T08:38:49.204772Z","shell.execute_reply.started":"2022-04-18T08:38:49.195372Z","shell.execute_reply":"2022-04-18T08:38:49.204143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Q2) Define an adam optimizer with learning rate 0.01\n\n\n","metadata":{"id":"2yivU9JPeYOi"}},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)","metadata":{"id":"IYDz1RZa7lH-","execution":{"iopub.status.busy":"2022-04-18T08:38:49.20977Z","iopub.execute_input":"2022-04-18T08:38:49.212038Z","iopub.status.idle":"2022-04-18T08:38:49.224685Z","shell.execute_reply.started":"2022-04-18T08:38:49.212Z","shell.execute_reply":"2022-04-18T08:38:49.224089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Q3) Define an iteration of the training loop\ninputs:\n+ imgInput  : network input image (noise prior)\n+ imgTarget : masked image\n+ imgMask   : mask\n+ stddev    : standard deviation of the noise (normal distribution) to be added dynamically to the input (helps regularization of the network)\n\noutputs:\n+ loss\n+ imgResult : produced image\n\nThe function compute the loss and update the networks parameters using the optimizer (already defined in Q2)\n\nVery important : Activate the @tf.function() decorator only when the code is 100% working (this decorators compile the computation graph, so iterations are computed faster, but also makes debugging more crumblesome)\n\nWhy keeping this print('*** Tracing ***') stuff ?\n=> When using the @tf.function() decorator, if the code is designed correctly, the computation graph should be computed only one or two times during program execution. When this graph is computed, the print is active, and you will see it. \n\nIf for some reasons (typically one of the function inputs is not a tensor) the graph is computed many times, you will see all the **** tracing **** in the output. \nIn that case you need to stop the program and fix it. Graph computation takes a lot of time and consumes memory. Soon or later, the memory usage will exceed the available memory and THE SESSION WILL CRASH.","metadata":{"id":"XYtyV6fyerH4"}},{"cell_type":"code","source":"@tf.function()\n\ndef NoiseInit(height, width):\n    Img=tf.random.uniform(shape=[height,width,3], minval=-0.1, maxval=0.1, dtype=tf.float32)\n    Imgs=tf.expand_dims(Img,axis=0)\n    return Imgs\n\ndef trainStep(imgInput,imgTarget,imgMask,stddev):\n    noise = tf.random.normal(shape=[1]+inputShape, stddev=stddev)  \n    \n    print('*************** Tracing *********************')\n    with tf.GradientTape() as tape:\n        imgResult = model(imgInput+noise, training=True)\n#         print(imgInput.shape)\n#         print(imgResult.shape)\n        \n        masked_error = tf.multiply((tf.math.add(imgTarget,-imgResult)), imgMask)\n        loss = tf.reduce_mean(tf.square(masked_error))\n     \n    gradients = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients,model.trainable_variables))\n        \n    return loss,imgResult","metadata":{"id":"ZBfTocFn7Gg-","execution":{"iopub.status.busy":"2022-04-18T08:38:49.228676Z","iopub.execute_input":"2022-04-18T08:38:49.230552Z","iopub.status.idle":"2022-04-18T08:38:49.24222Z","shell.execute_reply.started":"2022-04-18T08:38:49.230479Z","shell.execute_reply":"2022-04-18T08:38:49.241553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Q4) Inpainting optimization loop\nThis function is the main optimization loop. \nInputs:\n+ nbiter : number of optimization iterations with the Adam solver\n+ stddev : standard deviation of the gaussian noise w\n\nOutput :\n+ imgResult : final optimized image\n+ allLoss: list with all the losses all over the iterations\n\nThe iteration progress should be displayed using tqdm. Every 100 iteration, the display should be updated using the display function so the user can track the progress. ","metadata":{"id":"dGZ5hVNUjZPK"}},{"cell_type":"code","source":"def inpatining(nbiter,stddev):\n    allLoss = []\n    nsamples = 100\n    \n    for iter in tqdm(range(nbiter)):\n        loss, imgResult = trainStep(imgInput,imgTarget,imgMask,stddev)\n        allLoss.append(loss)\n            \n        if iter%100 == 0:\n            display(imgTarget,imgResult,allLoss)\n            \n    return imgResult[0],allLoss","metadata":{"id":"-ZBHvo0mBCI8","execution":{"iopub.status.busy":"2022-04-18T08:38:49.247738Z","iopub.execute_input":"2022-04-18T08:38:49.250094Z","iopub.status.idle":"2022-04-18T08:38:49.257656Z","shell.execute_reply.started":"2022-04-18T08:38:49.250027Z","shell.execute_reply":"2022-04-18T08:38:49.25699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Main program","metadata":{"id":"qR8mwcimpEgd"}},{"cell_type":"markdown","source":"## Q5) Read input and mask images","metadata":{"id":"B9ZaXx1qpfZI"}},{"cell_type":"code","source":"no=4\nif no==1:\n    # building. Pick a mask buildingMask1, buildingMask2 or buildingMask3\n    filenameImg=os.path.join(baseFolder,'building.png')\n    filenameMask=os.path.join(baseFolder,'buildingMask1.png')\nelif no==2:\n    # abstract wall paper\n    filenameImg=os.path.join(baseFolder,'0011_img.png')\n    filenameMask=os.path.join(baseFolder,'0011_mask.png')\nelif no==3:\n    # dog\n    filenameImg=os.path.join(baseFolder,'0071_img.png')\n    filenameMask=os.path.join(baseFolder,'0071_mask.png')\nelif no==4:\n    # bison\n    filenameImg=os.path.join(baseFolder,'0090_img.png')\n    filenameMask=os.path.join(baseFolder,'0090_mask.png')\nelif no==5:\n    filenameImg=os.path.join(baseFolder,'0063_img.png')\n    filenameMask=os.path.join(baseFolder,'0063_mask.png')\nelif no==6:\n    filenameImg=os.path.join(baseFolder,'0089_img.png')\n    filenameMask=os.path.join(baseFolder,'0089_mask.png')\n\n# read 2 images with read_image : original image + mask\nimgOrigine = read_image(filenameImg,True)\nimgMask = read_image(filenameMask,True,False)\n\n# create masked image\nimgTarget = tf.multiply(imgOrigine,imgMask)\n\n# Display in a figure with subplot : the original image, the mask and the target\nplt.figure(figsize=(10,15))\nplt.subplot(1,3,1)\nplt.imshow(imgOrigine[0])\nplt.axis('off')\nplt.subplot(1,3,2)\nplt.imshow(imgMask[0])\nplt.axis('off')\nplt.subplot(1,3,3)\nplt.imshow(imgTarget[0])\nplt.show()","metadata":{"id":"okuTOojRUMZQ","execution":{"iopub.status.busy":"2022-04-18T08:38:49.262222Z","iopub.execute_input":"2022-04-18T08:38:49.26461Z","iopub.status.idle":"2022-04-18T08:38:51.943154Z","shell.execute_reply.started":"2022-04-18T08:38:49.264574Z","shell.execute_reply":"2022-04-18T08:38:51.94245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Q6) Main program\n1) Générate network parameters & network\n2) Générate imgNoise, the input image\n3) Perform inpainting\n4) Display results\n\nNB : in Kaggle, you may get the image by opening the console tab (bottom of the screen) and right clicking on the image and chose save as..","metadata":{"id":"3n1UDnf_n3Hu"}},{"cell_type":"code","source":"stddev = 0/100 # 2/100\nnbiter = 8000\n\nnfilter = [128]*6\nupsample_factor = 2**(len(nfilter)-1)\ninputShape = [img_height//upsample_factor,img_width//upsample_factor,3]\n\nimgInput = NoiseInit(inputShape[0], inputShape[1])\n\nmodel = buildDecoder(inputShape,nfilter,display=False)\n\nimgResult, allLoss = inpatining(nbiter,stddev)\n\n# display final result\nplt.figure(figsize=[15,10])\nplt.imshow(imgResult)\nplt.show()","metadata":{"id":"ApoM4pbmj6xI","execution":{"iopub.status.busy":"2022-04-18T08:38:51.944397Z","iopub.execute_input":"2022-04-18T08:38:51.94479Z","iopub.status.idle":"2022-04-18T08:39:16.619417Z","shell.execute_reply.started":"2022-04-18T08:38:51.944754Z","shell.execute_reply":"2022-04-18T08:39:16.617571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stddev = 2/100\nnbiter = 8000\n\nnfilter = [128]*6\nupsample_factor = 2**(len(nfilter)-1)\ninputShape = [img_height//upsample_factor,img_width//upsample_factor,3]\n\nimgInput = NoiseInit(inputShape[0], inputShape[1])\n\nmodel = buildDecoder(inputShape,nfilter,display=False)\n\nimgResult, allLoss = inpatining(nbiter,stddev)\n\n# display final result\nplt.figure(figsize=[15,10])\nplt.imshow(imgResult)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:39:16.620726Z","iopub.status.idle":"2022-04-18T08:39:16.621155Z","shell.execute_reply.started":"2022-04-18T08:39:16.620914Z","shell.execute_reply":"2022-04-18T08:39:16.620937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Q7)\nThis approach won't perform well when the mask region is very large because we are upsampling the image. Since pixels are \"guessed\", it's better to use for small mask so the difference between produced image and the original image will not be big. ","metadata":{}},{"cell_type":"markdown","source":"## Q8)\nThe role of 1x1 first convolutional layer with n1[0] channels is to increase the number of channels of the image without changing its actual dimention (width and height). Further more, the number of channels of this layer should be equal to the number of the next layer because the next block is a residual block. And in order to perform an identity in parallel to 3 blocks including in the residual block, we should have a equal number of channel.","metadata":{}},{"cell_type":"markdown","source":"## Q9) \nThe structure can only work for n1[i] = n1[i-1] for the same reason as mentionned in Q8. Imagine we have n1[i] different than n1[i-1]. As in a residual block, we will perform the sum of the output of 3 convolutional blocks and the identity. If the input of the residual block has a different number of channels than the output, then the identity will have a different number of channels. Consequently, the operation cannot be performed.","metadata":{}},{"cell_type":"markdown","source":"## Q10) \nA colored image always has 3 or 4 channels. In our case, we use RGB so it number of channels should be 3.","metadata":{}},{"cell_type":"markdown","source":"## Q11) ","metadata":{}},{"cell_type":"code","source":"def residual_block(Input, k, n1, n2):\n    identity = tf.identity(Input)\n    \n    # Block 1\n    Input = layers.Conv2D(filters=n1, kernel_size=1, kernel_initializer=tf.keras.initializers.HeNormal(), strides=1, padding=\"same\", use_bias=\"False\")(Input)\n    Input = layers.BatchNormalization(momentum=0.9, epsilon=1e-5)(Input)\n    Input = layers.ReLU()(Input)\n    \n    # Block 2\n    Input = layers.Conv2D(filters=n2, kernel_size=k, kernel_initializer=tf.keras.initializers.HeNormal(), strides=1, padding=\"same\", use_bias=\"False\")(Input)\n    Input = layers.BatchNormalization(momentum=0.9, epsilon=1e-5)(Input)\n    Input = layers.ReLU()(Input)\n    \n    # Block 3\n    Input = layers.Conv2D(filters=n1, kernel_size=1, kernel_initializer=tf.keras.initializers.HeNormal(), strides=1, padding=\"same\", use_bias=\"False\")(Input)\n    Input = layers.BatchNormalization(momentum=0.9, epsilon=1e-5)(Input)\n    Input = layers.ReLU()(Input)\n    \n    # Residual\n    Input += identity\n    \n    return Input","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:39:16.622603Z","iopub.status.idle":"2022-04-18T08:39:16.62301Z","shell.execute_reply.started":"2022-04-18T08:39:16.622791Z","shell.execute_reply":"2022-04-18T08:39:16.622813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Q12)","metadata":{}},{"cell_type":"code","source":"def genereResidual2(inputShape, n1, n2, display=False):\n    # Input\n    Input = layers.Input(shape=inputShape)\n    \n    # Block 0: 1x1 convolution\n    x = layers.Conv2D(filters=n1[0], kernel_size=1, kernel_initializer=tf.keras.initializers.HeNormal(), strides=1, padding=\"same\", use_bias=\"False\")(Input)\n    \n    # Block 1\n    x = residual_block(x, 3, n1[0], n2[0])\n    \n    # From Block 2 until before Final Block\n    for i in range(1, len(n1)):\n        x = layers.UpSampling2D(interpolation=\"bilinear\")(x)\n        x = residual_block(x, 3, n1[i], n2[i])\n        \n    # Final block\n    x = layers.Conv2D(filters=3, kernel_size=1, kernel_initializer=tf.keras.initializers.HeNormal(), strides=1, padding=\"same\", use_bias=\"False\", activation=\"tanh\")(x)\n    \n    # Model\n    model = tf.keras.Model(Input, x)\n    \n    if display:\n        print(model.summary())\n        \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:39:16.624455Z","iopub.status.idle":"2022-04-18T08:39:16.624877Z","shell.execute_reply.started":"2022-04-18T08:39:16.624658Z","shell.execute_reply":"2022-04-18T08:39:16.624681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Q13)","metadata":{}},{"cell_type":"code","source":"stddev = 0/100\nnbiter = 8000\n\nn1 = [128]*6\nn2 = [64]*6\nupsample_factor = 2**(len(n1)-1)\ninputShape = [img_height//upsample_factor,img_width//upsample_factor,3]\n\nimgInput = NoiseInit(inputShape[0], inputShape[1])\n\nmodel = genereResidual2(inputShape, n1, n2, display=False)\n\nimgResult, allLoss = inpatining(nbiter,stddev)\n\n# display final result\nplt.figure(figsize=[15,10])\nplt.imshow(imgResult)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:39:16.626212Z","iopub.status.idle":"2022-04-18T08:39:16.626663Z","shell.execute_reply.started":"2022-04-18T08:39:16.626415Z","shell.execute_reply":"2022-04-18T08:39:16.626437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Q14) \"Advanced\" residual block","metadata":{}},{"cell_type":"code","source":"def residual_block_advanced(Input, k, n1, n2):\n    \n    # Additional Branch\n    additional_branch = tf.identity(Input)\n    additional_branch = layers.Conv2D(filters=n1, kernel_size=1, kernel_initializer=tf.keras.initializers.HeNormal(), strides=1, padding=\"same\", use_bias=\"False\")(additional_branch)\n    additional_branch = layers.BatchNormalization(momentum=0.9, epsilon=1e-5)(additional_branch)\n    additional_branch = layers.ReLU()(additional_branch)\n    \n    # Block 1\n    Input = layers.Conv2D(filters=n1, kernel_size=1, kernel_initializer=tf.keras.initializers.HeNormal(), strides=1, padding=\"same\", use_bias=\"False\")(Input)\n    Input = layers.BatchNormalization(momentum=0.9, epsilon=1e-5)(Input)\n    Input = layers.ReLU()(Input)\n    \n    # Block 2\n    Input = layers.Conv2D(filters=n2, kernel_size=k, kernel_initializer=tf.keras.initializers.HeNormal(), strides=1, padding=\"same\", use_bias=\"False\")(Input)\n    Input = layers.BatchNormalization(momentum=0.9, epsilon=1e-5)(Input)\n    Input = layers.ReLU()(Input)\n    \n    # Block 3\n    Input = layers.Conv2D(filters=n1, kernel_size=1, kernel_initializer=tf.keras.initializers.HeNormal(), strides=1, padding=\"same\", use_bias=\"False\")(Input)\n    Input = layers.BatchNormalization(momentum=0.9, epsilon=1e-5)(Input)\n    Input = layers.ReLU()(Input)\n    \n    # Residual\n    Input += additional_branch\n    \n    return Input","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:39:16.62787Z","iopub.status.idle":"2022-04-18T08:39:16.628504Z","shell.execute_reply.started":"2022-04-18T08:39:16.628262Z","shell.execute_reply":"2022-04-18T08:39:16.628288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def genereAdvancedResidual2(inputShape, n1, n2, display=False):\n    # Input\n    Input = layers.Input(shape=inputShape)\n    \n    # Block 0: 1x1 convolution\n    x = layers.Conv2D(filters=n1[0], kernel_size=1, kernel_initializer=tf.keras.initializers.HeNormal(), strides=1, padding=\"same\", use_bias=\"False\")(Input)\n    \n    # Block 1\n    x = residual_block_advanced(x, 3, n1[0], n2[0])\n    \n    # From Block 2 until before Final Block\n    for i in range(1, len(n1)):\n        x = layers.UpSampling2D(interpolation=\"bilinear\")(x)\n        x = residual_block_advanced(x, 3, n1[i], n2[i])\n        \n    # Final block\n    x = layers.Conv2D(filters=3, kernel_size=1, kernel_initializer=tf.keras.initializers.HeNormal(), strides=1, padding=\"same\", use_bias=\"False\", activation=\"tanh\")(x)\n    \n    # Model\n    model = tf.keras.Model(Input, x)\n    \n    if display:\n        print(model.summary())\n        \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:39:16.63009Z","iopub.status.idle":"2022-04-18T08:39:16.630716Z","shell.execute_reply.started":"2022-04-18T08:39:16.630458Z","shell.execute_reply":"2022-04-18T08:39:16.630481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stddev = 1/100\nnbiter = 8000\n\nn1 = [256//2**i for i in range(5)]\nn2 = [128//2**i for i in range(5)]\nupsample_factor = 2**(len(n1)-1)\ninputShape = [img_height//upsample_factor,img_width//upsample_factor,3]\n\nimgInput = NoiseInit(inputShape[0], inputShape[1])\n\nmodel = genereAdvancedResidual2(inputShape, n1, n2, display=False)\n\nimgResult, allLoss = inpatining(nbiter,stddev)\n\n# display final result\nplt.figure(figsize=[15,10])\nplt.imshow(imgResult)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:39:16.631762Z","iopub.status.idle":"2022-04-18T08:39:16.632475Z","shell.execute_reply.started":"2022-04-18T08:39:16.632235Z","shell.execute_reply":"2022-04-18T08:39:16.632259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Q15) UNet Architecture","metadata":{}},{"cell_type":"code","source":"def down_conv_block(x, nd, kd):\n    \n    # Block 1\n    x = layers.Conv2D(filters=nd, kernel_size=kd, kernel_initializer=tf.keras.initializers.HeNormal(), strides=2, padding=\"same\", use_bias=\"False\")(x)\n    x = layers.BatchNormalization(momentum=0.9, epsilon=1e-5)(x)\n    x = layers.ReLU()(x)\n    \n    # Block 2\n    x = layers.Conv2D(filters=nd, kernel_size=kd, kernel_initializer=tf.keras.initializers.HeNormal(), strides=1, padding=\"same\", use_bias=\"False\")(x)\n    x = layers.BatchNormalization(momentum=0.9, epsilon=1e-5)(x)\n    x = layers.ReLU()(x)\n    \n    return x\n\ndef up_conv_block(x, nu, ku):\n    \n    # Block 1\n    x = layers.Conv2D(filters=nu, kernel_size=ku, kernel_initializer=tf.keras.initializers.HeNormal(), strides=1, padding=\"same\", use_bias=\"False\")(x)\n    x = layers.BatchNormalization(momentum=0.9, epsilon=1e-5)(x)\n    x = layers.ReLU()(x)\n    \n    # Block 2\n    x = layers.Conv2D(filters=nu, kernel_size=1, kernel_initializer=tf.keras.initializers.HeNormal(), strides=1, padding=\"same\", use_bias=\"False\")(x)\n    x = layers.BatchNormalization(momentum=0.9, epsilon=1e-5)(x)\n    x = layers.ReLU()(x)\n    \n    # Block 3\n#     if first_block:\n    x = layers.UpSampling2D(interpolation=\"bilinear\")(x)\n    \n    return x\n    \ndef skip_block(x, ns):\n    \n    # Block 1\n    x = layers.Conv2D(filters=ns, kernel_size=1, kernel_initializer=tf.keras.initializers.HeNormal(), strides=1, padding=\"same\", use_bias=\"False\")(x)\n    x = layers.BatchNormalization(momentum=0.9, epsilon=1e-5)(x)\n    x = layers.ReLU()(x)\n    \n    return x","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:39:16.63377Z","iopub.status.idle":"2022-04-18T08:39:16.634523Z","shell.execute_reply.started":"2022-04-18T08:39:16.634248Z","shell.execute_reply":"2022-04-18T08:39:16.634273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def genereUNet(inputShape, nd, kd, nu, ku, ns, display=False):\n    # Input\n    Input = layers.Input(shape=inputShape)\n    \n    # Output lists:\n    output_down = []\n    output_skip = []\n    \n    x = down_conv_block(Input, nd[0], kd[0])\n    output_down.append(x)\n    \n    for i in range(1,len(nd)):\n        x = down_conv_block(x, nd[i], kd[i])\n        output_down.append(x)\n        \n    for i in range(len(ns)):\n        x = skip_block(output_down[i], ns[i])\n        output_skip.append(x)\n        \n    x = up_conv_block(output_skip[4], nu[4], ku[4])\n    \n    for i in reversed(range(1,len(nu)-1)):\n        x = up_conv_block(output_skip[i], nu[i], ku[i])\n        x = tf.keras.layers.Concatenate()([x, output_skip[i-1]])\n    \n    x = up_conv_block(output_skip[0], nu[0], ku[0])\n        \n    # Final block\n    x = layers.Conv2D(filters=3, kernel_size=1, kernel_initializer=tf.keras.initializers.HeNormal(), strides=1, padding=\"same\", use_bias=\"False\", activation=\"tanh\")(x)\n    \n    # Model\n    model = tf.keras.Model(Input, x)\n    \n    if display:\n        print(model.summary())\n        \n    return model, output_skip","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:39:16.63577Z","iopub.status.idle":"2022-04-18T08:39:16.636189Z","shell.execute_reply.started":"2022-04-18T08:39:16.635956Z","shell.execute_reply":"2022-04-18T08:39:16.635979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stddev = 1/100\nnbiter = 8000\n\nnu = [128]*5\nnd = [128]*5\nns = [4]*5\nkd = [3]*5\nku = [5]*5\n\ninputShape = [img_height, img_width, 3]\n\nimgInput = NoiseInit(inputShape[0], inputShape[1])\n\nmodel, output_skip = genereUNet(inputShape, nd, kd, nu, ku, ns, display=False)\n\nimgResult, allLoss = inpatining(nbiter,stddev)\n\n# display final result\nplt.figure(figsize=[15,10])\nplt.imshow(imgResult)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:39:16.637597Z","iopub.status.idle":"2022-04-18T08:39:16.637994Z","shell.execute_reply.started":"2022-04-18T08:39:16.637779Z","shell.execute_reply":"2022-04-18T08:39:16.6378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Q16) Inception","metadata":{}},{"cell_type":"code","source":"def inception_block(x, n1, n3, n5, nd, np):\n    \n    # Branch 1\n    x1 = layers.Conv2D(filters=n1, kernel_size=1, kernel_initializer=tf.keras.initializers.HeNormal(), strides=1, padding=\"same\", use_bias=\"False\")(x)\n    x1 = layers.BatchNormalization(momentum=0.9, epsilon=1e-5)(x1)\n    x1 = layers.ReLU()(x1)\n    \n    # Branch 2 - Block 1\n    x2 = layers.Conv2D(filters=nd, kernel_size=1, kernel_initializer=tf.keras.initializers.HeNormal(), strides=1, padding=\"same\", use_bias=\"False\")(x)\n    x2 = layers.BatchNormalization(momentum=0.9, epsilon=1e-5)(x2)\n    x2 = layers.ReLU()(x2)\n    \n    # Branch 2 - Block 2\n    x2 = layers.Conv2D(filters=n3, kernel_size=3, kernel_initializer=tf.keras.initializers.HeNormal(), strides=1, padding=\"same\", use_bias=\"False\")(x2)\n    x2 = layers.BatchNormalization(momentum=0.9, epsilon=1e-5)(x2)\n    x2 = layers.ReLU()(x2)\n    \n    # Branch 3 - Block 1\n    x3 = layers.Conv2D(filters=nd, kernel_size=1, kernel_initializer=tf.keras.initializers.HeNormal(), strides=1, padding=\"same\", use_bias=\"False\")(x)\n    x3 = layers.BatchNormalization(momentum=0.9, epsilon=1e-5)(x3)\n    x3 = layers.ReLU()(x3)\n    \n    # Branch 3 - Block 2\n    x3 = layers.Conv2D(filters=n5, kernel_size=3, kernel_initializer=tf.keras.initializers.HeNormal(), strides=1, padding=\"same\", use_bias=\"False\")(x3)\n    \n    # Branch 3 - Block 3\n    x3 = layers.Conv2D(filters=n5, kernel_size=3, kernel_initializer=tf.keras.initializers.HeNormal(), strides=1, padding=\"same\", use_bias=\"False\")(x3)\n    x3 = layers.BatchNormalization(momentum=0.9, epsilon=1e-5)(x3)\n    x3 = layers.ReLU()(x3)\n    \n    # Branch 4 - Block 1\n    x4 = layers.MaxPool2D(strides=1, padding=\"same\")(x)\n    \n    # Branch 4 - Block 2\n    x4 = layers.Conv2D(filters=np, kernel_size=1, kernel_initializer=tf.keras.initializers.HeNormal(), strides=1, padding=\"same\", use_bias=\"False\")(x4)\n    x4 = layers.BatchNormalization(momentum=0.9, epsilon=1e-5)(x4)\n    x4 = layers.ReLU()(x4)\n    \n    # Concatenation block\n    x = tf.keras.layers.Concatenate()([x1, x2, x3, x4])\n    \n    return x","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:39:16.639489Z","iopub.status.idle":"2022-04-18T08:39:16.639914Z","shell.execute_reply.started":"2022-04-18T08:39:16.639693Z","shell.execute_reply":"2022-04-18T08:39:16.639716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}